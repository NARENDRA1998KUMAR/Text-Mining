{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import libraries\n",
    "install necessary packages and import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy\n",
    "# !pip install credentials\n",
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # This is an easy-to-use Python library for accessing the Twitter API\n",
    "import pandas as pd     # To create and manage necessary data strucutres\n",
    "import numpy as np      # For scientific number computing\n",
    "\n",
    "\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Twitter App:\n",
    "In order to extract tweets for analysis, we need to access to Twitter account and create an app. The website to do this is https://apps.twitter.com/.\n",
    "\n",
    "From this app that we're creating we will save the following information in a script called credentials.py:\n",
    "\n",
    "Consumer Key (API Key)\n",
    "Consumer Secret (API Secret)\n",
    "Access Token\n",
    "Access Token Secret\n",
    "\n",
    "The following code extracts the tweet information and stores in an object called tweets. This object has following properties\n",
    "* id\n",
    "* tweet text\n",
    "* created_at\n",
    "* source\n",
    "* favorite_count\n",
    "* retweet_count\n",
    "* geo\n",
    "* coordinates\n",
    "* entities\n",
    "\n",
    "Methods available for the tweets object can be dispayed by the function dir(tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify ur api credentials\n",
    "consumer_key = '6dyaPblOXr95bYQtJWffckIh4'\n",
    "consumer_secret = 'ZDHkwXqisoVn4BIwBFb7GMRURRD0Ti6nvYIfahClZFYJkCv0hr'\n",
    "access_token = '2599485630-SLE7epwwoxXpxPHZWt8RDz0zFOuoP2uAfaNahxS'\n",
    "access_token_secret = 'k3FH1xmFAaqeAXZb0UbscLbEUENrD36YYuh1K5JyMjoMB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define function that can authenticate and extract tweeter data\n",
    "\n",
    "from credentials import *    # This will allow us to use the keys as variables\n",
    "\n",
    "# API's setup:\n",
    "def twitter_setup():\n",
    "    \n",
    "    # Utility function to setup the Twitter's API with our access keys provided.\n",
    "    # Authentication and access using keys:\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    \n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extractor object which is called tweets:\n",
    "extractor = twitter_setup()\n",
    "\n",
    "# We create a tweet list as follows:\n",
    "tweets = extractor.user_timeline(screen_name=\"realDonaldTrump\", count=200)\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))\n",
    "\n",
    "# We print the most recent 5 tweets:\n",
    "print(\"5 recent tweets:\\n\")\n",
    "for tweet in tweets[:5]:\n",
    "    print(tweet.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting and structuring tweet data\n",
    "Here a pandas dataframe is structed to receive all the tweet information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a pandas dataframe as follows:\n",
    "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "# We display the first 10 elements of the dataframe:\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print info from the first tweet:\n",
    "print(tweets[0].id)\n",
    "print(tweets[0].created_at)\n",
    "print(tweets[0].source)\n",
    "print(tweets[0].favorite_count)\n",
    "print(tweets[0].retweet_count)\n",
    "print(tweets[0].geo)\n",
    "print(tweets[0].coordinates)\n",
    "print(tweets[0].entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add relevant data:\n",
    "data['len']  = np.array([len(tweet.text) for tweet in tweets])\n",
    "data['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "data['Likes']  = np.array([tweet.favorite_count for tweet in tweets])\n",
    "data['RTs']    = np.array([tweet.retweet_count for tweet in tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some statistics for the tweet data extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the mean of lengths:\n",
    "mean = np.mean(data['len'])\n",
    "\n",
    "print(\"The avarage length of tweets: {}\".format(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We extract the tweet with more FAVs and more RTs:\n",
    "\n",
    "fav_max = np.max(data['Likes'])\n",
    "rt_max  = np.max(data['RTs'])\n",
    "\n",
    "fav = data[data.Likes == fav_max].index[0]\n",
    "rt  = data[data.RTs == rt_max].index[0]\n",
    "\n",
    "# Max FAVs:\n",
    "print(\"The tweet with more likes is: \\n{}\".format(data['Tweets'][fav]))\n",
    "print(\"Number of likes: {}\".format(fav_max))\n",
    "print(\"{} characters.\\n\".format(data['len'][fav]))\n",
    "\n",
    "# Max RTs:\n",
    "print(\"The tweet with more retweets is: \\n{}\".format(data['Tweets'][rt]))\n",
    "print(\"Number of retweets: {}\".format(rt_max))\n",
    "print(\"{} characters.\\n\".format(data['len'][rt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of tweet data:\n",
    "How tweets and retweet are happening as the time progresses. Create time series for tweet length, number of likes and retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create time series for data:\n",
    "\n",
    "tlen = pd.Series(data=data['len'].values, index=data['Date'])\n",
    "tfav = pd.Series(data=data['Likes'].values, index=data['Date'])\n",
    "tret = pd.Series(data=data['RTs'].values, index=data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengths along time:\n",
    "tlen.plot(figsize=(16,4), color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likes vs retweets visualization:\n",
    "tfav.plot(figsize=(16,4), label=\"Likes\", legend=True)\n",
    "tret.plot(figsize=(16,4), label=\"Retweets\", legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple sentiment analysis\n",
    "Textblob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks. We will use this module to perform some basic sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    \n",
    "    # Utility function to clean the text in a tweet by removing links and special characters using regex.\n",
    "\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cleaning\n",
    "# str1 = \"abc@def:a?/,    gef;:'' I am a bachelor a@b\"\n",
    "# ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", str1).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tweet):\n",
    "\n",
    "   #Utility function to classify the polarity of a tweet using textblob.\n",
    "\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = 'not bad'\n",
    "print(TextBlob(word1).sentiment.polarity)\n",
    "print(TextBlob(word1).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a column with the result of the analysis:\n",
    "data['SA'] = np.array([ analyze_sentiment(tweet) for tweet in data['Tweets'] ])\n",
    "\n",
    "# We display the updated dataframe with the new column:\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct lists with classified tweets:\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['SA'][index] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(data['Tweets'])))\n",
    "print(\"Percentage of negative tweets: {}%\".format(len(neg_tweets)*100/len(data['Tweets'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############  End of Lab Session    ###################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
